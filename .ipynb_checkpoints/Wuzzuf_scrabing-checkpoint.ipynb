{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/YahiaNaiem/Wuzzuf/blob/main/Wuzzuf_scrabing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MfQGQ9t5fZEE"
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X21XT2gYf_Ib",
    "outputId": "c7fcc9d6-a1de-4fb0-a29c-828841b4e281"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the job :  Data scientist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data%20scientist\n"
     ]
    }
   ],
   "source": [
    "#selecting the job to search for it's skills\n",
    "\n",
    "job = input(\"Enter the job : \")\n",
    "try:\n",
    "  job_search = job.split()[0] + \"%20\" + job.split()[1]\n",
    "except IndexError:\n",
    "  job_search = job\n",
    "print(job_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "o5EpvdkbgZsY"
   },
   "outputs": [],
   "source": [
    "#making the request to get the HTML for page of the wanted job and parsing it using BeautifulSoup\n",
    "\n",
    "response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start=0\")\n",
    "\n",
    "soup = BeautifulSoup(response.text , \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9bQRg8Jf2Sa",
    "outputId": "63a1dd68-78ce-46cf-f0b6-3e67149c0873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "#getting the number of jobs to loop on\n",
    "num_of_jobs_text = soup.find(\"strong\").get_text()\n",
    "Num_of_Jobs = int(num_of_jobs_text.replace(',', ''))\n",
    "print(Num_of_Jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "S8IsEboKf5pw"
   },
   "outputs": [],
   "source": [
    "#defining variables\n",
    "\n",
    "jops_counter = 1\n",
    "page_number = 0\n",
    "skills_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "p57Y62Yliqyo"
   },
   "outputs": [],
   "source": [
    "    #<li class=\"css-8neukt\">Showing 1 - 15 of 1060</li>\n",
    "\n",
    "response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start={page_number}\")\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "page_jobs = soup.find_all(\"div\", attrs={\"class\": \"css-1gatmva e1v1l3u10\"})\n",
    "job_pages_number = int(soup.find(\"li\", attrs={\"class\": \"css-8neukt\"}).text.split(\"-\")[1][0:3])\n",
    "#print(job_pages_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wRIJyj0g7iI",
    "outputId": "0356738a-2928-4d6c-fee9-831a327c4e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 jobs were scraped\n",
      "1 pages were scraped\n",
      "30 jobs were scraped\n",
      "2 pages were scraped\n",
      "45 jobs were scraped\n",
      "3 pages were scraped\n",
      "60 jobs were scraped\n",
      "4 pages were scraped\n",
      "75 jobs were scraped\n",
      "5 pages were scraped\n",
      "85 jobs were scraped\n",
      "6 pages were scraped\n"
     ]
    }
   ],
   "source": [
    "while jops_counter <= Num_of_Jobs: #loop for the number of jobs in all pages\n",
    "    response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start={page_number}\")\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    page_jobs = soup.find_all(\"div\", attrs={\"class\": \"css-1gatmva e1v1l3u10\"})\n",
    "\n",
    "    for job in page_jobs: #loop for jobs in each page\n",
    "        jops_counter += 1\n",
    "        skills_tags = job.find(\"div\", attrs={\"class\": \"css-y4udm8\"}).find_all(\"div\", attrs={})[1].find_all(\"a\", attrs={\"class\": \"css-5x9pm1\"})[0:4]\n",
    "\n",
    "        try:\n",
    "            skills_text = [skill.get_text().lstrip(' Â· ') for skill in skills_tags]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "        # Update skills_count dictionary\n",
    "        for skill in skills_text:\n",
    "            skills_count[skill.lower()] = skills_count.get(skill.lower(), 0) + 1\n",
    "\n",
    "    page_number += 1\n",
    "    print(f\"{jops_counter - 1} jobs were scraped\")\n",
    "    print(f\"{page_number} pages were scraped\")\n",
    "\n",
    "sorted_skills = dict(sorted(skills_count.items(), key = lambda item: item[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jp10sEYOmLIa",
    "outputId": "fd62150d-9f4e-4122-9491-89b7d50254f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer science': 46, 'information technology (it)': 44, 'engineering': 18, 'python': 16, 'sql': 15, 'analysis': 8, 'sales': 7, 'marketing': 7, 'data analysis': 6, 'finance': 6, 'financial analysis': 6, 'accounting': 6, 'software engineering': 5, 'software development': 5, 'project management': 5, 'customer service': 5, 'sales skills': 5, 'computer engineering': 4, 'financial management': 4, 'machine learning': 4, 'science': 4, 'javascript': 4, 'human resources (hr)': 3, 'full stack': 3, 'ai': 3, 'artificial intelligence': 3, 'manufacturing': 3, 'power bi': 2, 'bi': 2, 'recruitment': 2, 'commerce': 2, 'azure': 2, 'business intelligence': 2, 'html': 2, 'hse': 2, 'business development': 2, 'management': 2, 'chemistry': 2, 'dcs': 2, 'electrical engineering': 2, 'business analysis': 2, 'mechanical engineering': 2, 'social media': 2, 'e-marketing': 2, 'customer care': 2, 'customer support': 2, 'mathematics': 1, 'data science': 1, 'ssrs': 1, 'labor law': 1, 'training': 1, 'data mining': 1, 'database': 1, 'data': 1, 'data visualization': 1, 'big data': 1, 'data modeling': 1, 'php': 1, 'jquery': 1, 'mysql': 1, 'css': 1, 'environmental': 1, 'react': 1, 'livewire': 1, 'front-end development': 1, 'power apps': 1, 'oracle': 1, 'chemical': 1, 'chemical engineering': 1, 'flavors': 1, 'asp': 1, 'asp.net': 1, '.net': 1, 'blazor': 1, 'mvc': 1, 'asp.net core': 1, 'c#.net': 1, 'business': 1, 'pneumatic': 1, 'hydraulic': 1, 'mechanical power engineering': 1, 'r&amp;d': 1, 'deep learning': 1, 'computer vision': 1, 'agricultural engineer': 1, 'agricultural engineering': 1, 'agronomist': 1, 'laravel': 1, 'laravel 5': 1, 'laravel php': 1, 'design': 1, 'pharmacy': 1, 'research': 1, 'pmp': 1, 'c#': 1, 'production': 1, 'market research': 1, 'call center': 1, 'talent acquisition': 1, 'interviewing': 1, 'health &amp; safety': 1, 'sales target': 1}\n"
     ]
    }
   ],
   "source": [
    "print(sorted_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4ZFJBsFemgtt"
   },
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9OhYM9AwLUZW7GvTJJlQk",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
