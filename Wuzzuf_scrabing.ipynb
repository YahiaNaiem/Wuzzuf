{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/YahiaNaiem/Wuzzuf/blob/main/Wuzzuf_scrabing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def insert_into_excel(data_dict, excel_file):\n",
    "    # Create a new Workbook object\n",
    "    workbook = openpyxl.Workbook()\n",
    "\n",
    "    # Create a new sheet\n",
    "    sheet = workbook.active\n",
    "\n",
    "    # Iterate through the dictionary and insert data into the sheet\n",
    "    for row_index, (key, value) in enumerate(data_dict.items(), start=1):\n",
    "        sheet.cell(row=row_index, column=1, value=key)\n",
    "        sheet.cell(row=row_index, column=2, value=value)\n",
    "\n",
    "    # Save the workbook to the specified Excel file\n",
    "    workbook.save(excel_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_list = [\"data scientist\", \"web development\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wRIJyj0g7iI",
    "outputId": "0356738a-2928-4d6c-fee9-831a327c4e1f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #making the request to get the HTML for page of the wanted job and parsing it using BeautifulSoup\n",
    "# response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start=0\")\n",
    "# soup = BeautifulSoup(response.text , \"html.parser\")  #to use in defining the needed values(Num_of_Jobs)\n",
    "\n",
    "# #getting the number of jobs to loop on\n",
    "# num_of_jobs_text = soup.find(\"strong\").get_text()\n",
    "# Num_of_Jobs = int(num_of_jobs_text.replace(',', ''))\n",
    "\n",
    "def insert_skills(jobs_list):\n",
    "    for job_search in jobs_list:\n",
    "        response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start=0\")\n",
    "        soup = BeautifulSoup(response.text , \"html.parser\")  #to use in defining the needed values(Num_of_Jobs)\n",
    "        #getting the number of jobs to loop on\n",
    "        num_of_jobs_text = soup.find(\"strong\").get_text()\n",
    "        Num_of_Jobs = int(num_of_jobs_text.replace(',', ''))\n",
    "        jops_counter = 1\n",
    "        page_number = 0\n",
    "        skills_count = {}\n",
    "        while jops_counter <= Num_of_Jobs: #loop for the number of jobs in all pages\n",
    "            response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start={page_number}\")\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            page_jobs = soup.find_all(\"div\", attrs={\"class\": \"css-1gatmva e1v1l3u10\"})\n",
    "        \n",
    "            for job in page_jobs: #loop for jobs in each page\n",
    "                jops_counter += 1\n",
    "                skills_tags = job.find(\"div\", attrs={\"class\": \"css-y4udm8\"}).find_all(\"div\", attrs={})[1].find_all(\"a\", attrs={\"class\": \"css-5x9pm1\"})[0:4]\n",
    "        \n",
    "                try:\n",
    "                    skills_text = [skill.get_text().lstrip(' Â· ') for skill in skills_tags]\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        \n",
    "                # Update skills_count dictionary\n",
    "                for skill in skills_text:\n",
    "                    skills_count[skill.lower()] = skills_count.get(skill.lower(), 0) + 1\n",
    "        \n",
    "            page_number += 1\n",
    "            print(f\"{jops_counter - 1} jobs were scraped\")\n",
    "            print(f\"{page_number} pages were scraped\")\n",
    "        \n",
    "        sorted_skills = dict(sorted(skills_count.items(), key = lambda item: item[1], reverse = True))\n",
    "        reduced_dict = {key: value for key, value in sorted_skills.items() if value > 4}\n",
    "        insert_into_excel(reduced_dict, \"data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 jobs were scraped\n",
      "1 pages were scraped\n",
      "30 jobs were scraped\n",
      "2 pages were scraped\n",
      "45 jobs were scraped\n",
      "3 pages were scraped\n",
      "60 jobs were scraped\n",
      "4 pages were scraped\n",
      "75 jobs were scraped\n",
      "5 pages were scraped\n",
      "90 jobs were scraped\n",
      "6 pages were scraped\n",
      "105 jobs were scraped\n",
      "7 pages were scraped\n",
      "120 jobs were scraped\n",
      "8 pages were scraped\n",
      "135 jobs were scraped\n",
      "9 pages were scraped\n",
      "150 jobs were scraped\n",
      "10 pages were scraped\n",
      "165 jobs were scraped\n",
      "11 pages were scraped\n",
      "180 jobs were scraped\n",
      "12 pages were scraped\n",
      "195 jobs were scraped\n",
      "13 pages were scraped\n",
      "210 jobs were scraped\n",
      "14 pages were scraped\n",
      "225 jobs were scraped\n",
      "15 pages were scraped\n",
      "240 jobs were scraped\n",
      "16 pages were scraped\n",
      "255 jobs were scraped\n",
      "17 pages were scraped\n",
      "270 jobs were scraped\n",
      "18 pages were scraped\n",
      "285 jobs were scraped\n",
      "19 pages were scraped\n",
      "300 jobs were scraped\n",
      "20 pages were scraped\n",
      "315 jobs were scraped\n",
      "21 pages were scraped\n",
      "330 jobs were scraped\n",
      "22 pages were scraped\n",
      "345 jobs were scraped\n",
      "23 pages were scraped\n",
      "360 jobs were scraped\n",
      "24 pages were scraped\n",
      "375 jobs were scraped\n",
      "25 pages were scraped\n",
      "390 jobs were scraped\n",
      "26 pages were scraped\n",
      "405 jobs were scraped\n",
      "27 pages were scraped\n",
      "420 jobs were scraped\n",
      "28 pages were scraped\n",
      "435 jobs were scraped\n",
      "29 pages were scraped\n",
      "450 jobs were scraped\n",
      "30 pages were scraped\n",
      "465 jobs were scraped\n",
      "31 pages were scraped\n",
      "480 jobs were scraped\n",
      "32 pages were scraped\n",
      "495 jobs were scraped\n",
      "33 pages were scraped\n",
      "510 jobs were scraped\n",
      "34 pages were scraped\n",
      "525 jobs were scraped\n",
      "35 pages were scraped\n",
      "540 jobs were scraped\n",
      "36 pages were scraped\n",
      "555 jobs were scraped\n",
      "37 pages were scraped\n",
      "570 jobs were scraped\n",
      "38 pages were scraped\n",
      "585 jobs were scraped\n",
      "39 pages were scraped\n",
      "600 jobs were scraped\n",
      "40 pages were scraped\n",
      "615 jobs were scraped\n",
      "41 pages were scraped\n",
      "630 jobs were scraped\n",
      "42 pages were scraped\n",
      "645 jobs were scraped\n",
      "43 pages were scraped\n",
      "660 jobs were scraped\n",
      "44 pages were scraped\n",
      "675 jobs were scraped\n",
      "45 pages were scraped\n",
      "690 jobs were scraped\n",
      "46 pages were scraped\n",
      "705 jobs were scraped\n",
      "47 pages were scraped\n",
      "720 jobs were scraped\n",
      "48 pages were scraped\n",
      "735 jobs were scraped\n",
      "49 pages were scraped\n",
      "750 jobs were scraped\n",
      "50 pages were scraped\n",
      "765 jobs were scraped\n",
      "51 pages were scraped\n",
      "780 jobs were scraped\n",
      "52 pages were scraped\n",
      "795 jobs were scraped\n",
      "53 pages were scraped\n",
      "810 jobs were scraped\n",
      "54 pages were scraped\n",
      "825 jobs were scraped\n",
      "55 pages were scraped\n",
      "840 jobs were scraped\n",
      "56 pages were scraped\n",
      "855 jobs were scraped\n",
      "57 pages were scraped\n",
      "870 jobs were scraped\n",
      "58 pages were scraped\n",
      "885 jobs were scraped\n",
      "59 pages were scraped\n",
      "900 jobs were scraped\n",
      "60 pages were scraped\n",
      "915 jobs were scraped\n",
      "61 pages were scraped\n",
      "930 jobs were scraped\n",
      "62 pages were scraped\n",
      "945 jobs were scraped\n",
      "63 pages were scraped\n",
      "960 jobs were scraped\n",
      "64 pages were scraped\n",
      "975 jobs were scraped\n",
      "65 pages were scraped\n",
      "990 jobs were scraped\n",
      "66 pages were scraped\n",
      "1005 jobs were scraped\n",
      "67 pages were scraped\n",
      "1020 jobs were scraped\n",
      "68 pages were scraped\n",
      "1035 jobs were scraped\n",
      "69 pages were scraped\n",
      "1050 jobs were scraped\n",
      "70 pages were scraped\n",
      "1065 jobs were scraped\n",
      "71 pages were scraped\n",
      "1080 jobs were scraped\n",
      "72 pages were scraped\n",
      "1095 jobs were scraped\n",
      "73 pages were scraped\n",
      "1110 jobs were scraped\n",
      "74 pages were scraped\n",
      "1125 jobs were scraped\n",
      "75 pages were scraped\n",
      "1140 jobs were scraped\n",
      "76 pages were scraped\n",
      "1155 jobs were scraped\n",
      "77 pages were scraped\n",
      "1170 jobs were scraped\n",
      "78 pages were scraped\n",
      "1185 jobs were scraped\n",
      "79 pages were scraped\n",
      "1200 jobs were scraped\n",
      "80 pages were scraped\n",
      "1215 jobs were scraped\n",
      "81 pages were scraped\n",
      "1230 jobs were scraped\n",
      "82 pages were scraped\n",
      "1245 jobs were scraped\n",
      "83 pages were scraped\n",
      "1260 jobs were scraped\n",
      "84 pages were scraped\n",
      "1270 jobs were scraped\n",
      "85 pages were scraped\n",
      "15 jobs were scraped\n",
      "1 pages were scraped\n",
      "30 jobs were scraped\n",
      "2 pages were scraped\n",
      "45 jobs were scraped\n",
      "3 pages were scraped\n",
      "60 jobs were scraped\n",
      "4 pages were scraped\n",
      "75 jobs were scraped\n",
      "5 pages were scraped\n",
      "90 jobs were scraped\n",
      "6 pages were scraped\n",
      "105 jobs were scraped\n",
      "7 pages were scraped\n",
      "120 jobs were scraped\n",
      "8 pages were scraped\n",
      "135 jobs were scraped\n",
      "9 pages were scraped\n",
      "150 jobs were scraped\n",
      "10 pages were scraped\n",
      "165 jobs were scraped\n",
      "11 pages were scraped\n",
      "180 jobs were scraped\n",
      "12 pages were scraped\n",
      "195 jobs were scraped\n",
      "13 pages were scraped\n",
      "210 jobs were scraped\n",
      "14 pages were scraped\n",
      "225 jobs were scraped\n",
      "15 pages were scraped\n",
      "240 jobs were scraped\n",
      "16 pages were scraped\n",
      "255 jobs were scraped\n",
      "17 pages were scraped\n",
      "270 jobs were scraped\n",
      "18 pages were scraped\n",
      "285 jobs were scraped\n",
      "19 pages were scraped\n",
      "300 jobs were scraped\n",
      "20 pages were scraped\n",
      "315 jobs were scraped\n",
      "21 pages were scraped\n",
      "330 jobs were scraped\n",
      "22 pages were scraped\n",
      "345 jobs were scraped\n",
      "23 pages were scraped\n",
      "360 jobs were scraped\n",
      "24 pages were scraped\n",
      "375 jobs were scraped\n",
      "25 pages were scraped\n",
      "390 jobs were scraped\n",
      "26 pages were scraped\n",
      "405 jobs were scraped\n",
      "27 pages were scraped\n",
      "420 jobs were scraped\n",
      "28 pages were scraped\n",
      "435 jobs were scraped\n",
      "29 pages were scraped\n",
      "450 jobs were scraped\n",
      "30 pages were scraped\n",
      "465 jobs were scraped\n",
      "31 pages were scraped\n",
      "480 jobs were scraped\n",
      "32 pages were scraped\n",
      "495 jobs were scraped\n",
      "33 pages were scraped\n",
      "510 jobs were scraped\n",
      "34 pages were scraped\n",
      "525 jobs were scraped\n",
      "35 pages were scraped\n",
      "540 jobs were scraped\n",
      "36 pages were scraped\n",
      "555 jobs were scraped\n",
      "37 pages were scraped\n",
      "570 jobs were scraped\n",
      "38 pages were scraped\n",
      "585 jobs were scraped\n",
      "39 pages were scraped\n",
      "600 jobs were scraped\n",
      "40 pages were scraped\n",
      "615 jobs were scraped\n",
      "41 pages were scraped\n",
      "630 jobs were scraped\n",
      "42 pages were scraped\n",
      "645 jobs were scraped\n",
      "43 pages were scraped\n",
      "660 jobs were scraped\n",
      "44 pages were scraped\n",
      "675 jobs were scraped\n",
      "45 pages were scraped\n",
      "690 jobs were scraped\n",
      "46 pages were scraped\n",
      "705 jobs were scraped\n",
      "47 pages were scraped\n",
      "720 jobs were scraped\n",
      "48 pages were scraped\n",
      "735 jobs were scraped\n",
      "49 pages were scraped\n",
      "750 jobs were scraped\n",
      "50 pages were scraped\n",
      "765 jobs were scraped\n",
      "51 pages were scraped\n",
      "780 jobs were scraped\n",
      "52 pages were scraped\n",
      "795 jobs were scraped\n",
      "53 pages were scraped\n",
      "810 jobs were scraped\n",
      "54 pages were scraped\n",
      "825 jobs were scraped\n",
      "55 pages were scraped\n",
      "840 jobs were scraped\n",
      "56 pages were scraped\n",
      "855 jobs were scraped\n",
      "57 pages were scraped\n",
      "870 jobs were scraped\n",
      "58 pages were scraped\n",
      "874 jobs were scraped\n",
      "59 pages were scraped\n"
     ]
    }
   ],
   "source": [
    "insert_skills([\"data science\", \"web development\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def insert_skills(jobs_list):\n",
    "    all_jobs_data = {}  # Initialize dictionary to store all jobs data\n",
    "    for job_search in jobs_list:\n",
    "        response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start=0\")\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        num_of_jobs_text = soup.find(\"strong\").get_text()\n",
    "        Num_of_Jobs = int(num_of_jobs_text.replace(',', ''))\n",
    "        jobs_data = {}  # Initialize dictionary to store job data for current job search\n",
    "        jops_counter = 1\n",
    "        page_number = 0\n",
    "        while jops_counter <= Num_of_Jobs: # Loop for the number of jobs in all pages\n",
    "            response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start={page_number}\")\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            page_jobs = soup.find_all(\"div\", attrs={\"class\": \"css-1gatmva e1v1l3u10\"})\n",
    "        \n",
    "            for job in page_jobs: # Loop for jobs in each page\n",
    "                job_title = job.find(\"h2\", attrs={\"class\": \"css-m604qf\"}).text.strip()\n",
    "                skills_tags = job.find(\"div\", attrs={\"class\": \"css-y4udm8\"}).find_all(\"div\", attrs={})[1].find_all(\"a\", attrs={\"class\": \"css-5x9pm1\"})[0:4]\n",
    "                skills_text = [skill.get_text().lstrip(' Â· ') for skill in skills_tags]\n",
    "                jobs_data[job_title] = skills_text\n",
    "        \n",
    "                jops_counter += 1\n",
    "                if jops_counter > Num_of_Jobs:  # Break loop if all jobs are scraped\n",
    "                    break\n",
    "        \n",
    "            page_number += 1\n",
    "        \n",
    "        all_jobs_data[job_search] = jobs_data  # Store job data for current job search in the main dictionary\n",
    "\n",
    "    # Save all jobs data to JSON file\n",
    "    with open('jobs_data.json', 'w') as json_file:\n",
    "        json.dump(all_jobs_data, json_file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "jobs_list = ['data scientist', 'software engineer']  # List of job searches\n",
    "insert_skills(jobs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9OhYM9AwLUZW7GvTJJlQk",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
