{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9OhYM9AwLUZW7GvTJJlQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahiaNaiem/Wuzzuf/blob/main/Wuzzuf_scrabing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "MfQGQ9t5fZEE"
      },
      "outputs": [],
      "source": [
        "#importing packages\n",
        "\n",
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting the job to search for it's skills\n",
        "\n",
        "job = input(\"Enter the job : \")\n",
        "try:\n",
        "  job_search = job.split()[0] + \"%20\" + job.split()[1]\n",
        "except IndexError:\n",
        "  job_search = job\n",
        "print(job_search)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X21XT2gYf_Ib",
        "outputId": "c7fcc9d6-a1de-4fb0-a29c-828841b4e281"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the job : web development\n",
            "web%20development\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making the request to get the HTML for page of the wanted job and parsing it using BeautifulSoup\n",
        "\n",
        "response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start=0\")\n",
        "\n",
        "soup = BeautifulSoup(response.text , \"html.parser\")"
      ],
      "metadata": {
        "id": "o5EpvdkbgZsY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the number of jobs to loop on\n",
        "num_of_jobs_text = soup.find(\"strong\").get_text()\n",
        "Num_of_Jobs = int(num_of_jobs_text.replace(',', ''))\n",
        "print(Num_of_Jobs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9bQRg8Jf2Sa",
        "outputId": "63a1dd68-78ce-46cf-f0b6-3e67149c0873"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining variables\n",
        "\n",
        "jops_counter = 1\n",
        "page_number = 0\n",
        "skills_count = {}"
      ],
      "metadata": {
        "id": "S8IsEboKf5pw"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    #<li class=\"css-8neukt\">Showing 1 - 15 of 1060</li>\n",
        "\n",
        "response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start={page_number}\")\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "page_jobs = soup.find_all(\"div\", attrs={\"class\": \"css-1gatmva e1v1l3u10\"})\n",
        "job_pages_number = int(soup.find(\"li\", attrs={\"class\": \"css-8neukt\"}).text.split(\"-\")[1][0:3])\n",
        "#print(job_pages_number)"
      ],
      "metadata": {
        "id": "p57Y62Yliqyo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while jops_counter <= Num_of_Jobs: #loop for the number of jobs in all pages\n",
        "    response = requests.get(f\"https://wuzzuf.net/search/jobs/?a=hpb&q={job_search}&start={page_number}\")\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "    page_jobs = soup.find_all(\"div\", attrs={\"class\": \"css-1gatmva e1v1l3u10\"})\n",
        "\n",
        "    for job in page_jobs: #loop for jobs in each page\n",
        "        jops_counter += 1\n",
        "        skills_tags = job.find(\"div\", attrs={\"class\": \"css-y4udm8\"}).find_all(\"div\", attrs={})[1].find_all(\"a\", attrs={\"class\": \"css-5x9pm1\"})[0:4]\n",
        "\n",
        "        try:\n",
        "            skills_text = [skill.get_text().lstrip(' Â· ') for skill in skills_tags]\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "\n",
        "        # Update skills_count dictionary\n",
        "        for skill in skills_text:\n",
        "            skills_count[skill.lower()] = skills_count.get(skill.lower(), 0) + 1\n",
        "\n",
        "    page_number += 1\n",
        "    print(f\"{jops_counter - 1} jobs were scraped\")\n",
        "    print(f\"{page_number} pages were scraped\")\n",
        "\n",
        "sorted_skills = dict(sorted(skills_count.items(), key = lambda item: item[1], reverse = True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wRIJyj0g7iI",
        "outputId": "0356738a-2928-4d6c-fee9-831a327c4e1f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 jobs were scraped\n",
            "1 pages were scraped\n",
            "30 jobs were scraped\n",
            "2 pages were scraped\n",
            "45 jobs were scraped\n",
            "3 pages were scraped\n",
            "60 jobs were scraped\n",
            "4 pages were scraped\n",
            "75 jobs were scraped\n",
            "5 pages were scraped\n",
            "90 jobs were scraped\n",
            "6 pages were scraped\n",
            "105 jobs were scraped\n",
            "7 pages were scraped\n",
            "120 jobs were scraped\n",
            "8 pages were scraped\n",
            "135 jobs were scraped\n",
            "9 pages were scraped\n",
            "150 jobs were scraped\n",
            "10 pages were scraped\n",
            "165 jobs were scraped\n",
            "11 pages were scraped\n",
            "180 jobs were scraped\n",
            "12 pages were scraped\n",
            "195 jobs were scraped\n",
            "13 pages were scraped\n",
            "210 jobs were scraped\n",
            "14 pages were scraped\n",
            "225 jobs were scraped\n",
            "15 pages were scraped\n",
            "240 jobs were scraped\n",
            "16 pages were scraped\n",
            "255 jobs were scraped\n",
            "17 pages were scraped\n",
            "270 jobs were scraped\n",
            "18 pages were scraped\n",
            "285 jobs were scraped\n",
            "19 pages were scraped\n",
            "300 jobs were scraped\n",
            "20 pages were scraped\n",
            "315 jobs were scraped\n",
            "21 pages were scraped\n",
            "330 jobs were scraped\n",
            "22 pages were scraped\n",
            "345 jobs were scraped\n",
            "23 pages were scraped\n",
            "360 jobs were scraped\n",
            "24 pages were scraped\n",
            "375 jobs were scraped\n",
            "25 pages were scraped\n",
            "390 jobs were scraped\n",
            "26 pages were scraped\n",
            "405 jobs were scraped\n",
            "27 pages were scraped\n",
            "420 jobs were scraped\n",
            "28 pages were scraped\n",
            "435 jobs were scraped\n",
            "29 pages were scraped\n",
            "450 jobs were scraped\n",
            "30 pages were scraped\n",
            "465 jobs were scraped\n",
            "31 pages were scraped\n",
            "480 jobs were scraped\n",
            "32 pages were scraped\n",
            "495 jobs were scraped\n",
            "33 pages were scraped\n",
            "510 jobs were scraped\n",
            "34 pages were scraped\n",
            "525 jobs were scraped\n",
            "35 pages were scraped\n",
            "540 jobs were scraped\n",
            "36 pages were scraped\n",
            "555 jobs were scraped\n",
            "37 pages were scraped\n",
            "570 jobs were scraped\n",
            "38 pages were scraped\n",
            "585 jobs were scraped\n",
            "39 pages were scraped\n",
            "600 jobs were scraped\n",
            "40 pages were scraped\n",
            "615 jobs were scraped\n",
            "41 pages were scraped\n",
            "630 jobs were scraped\n",
            "42 pages were scraped\n",
            "645 jobs were scraped\n",
            "43 pages were scraped\n",
            "660 jobs were scraped\n",
            "44 pages were scraped\n",
            "675 jobs were scraped\n",
            "45 pages were scraped\n",
            "690 jobs were scraped\n",
            "46 pages were scraped\n",
            "705 jobs were scraped\n",
            "47 pages were scraped\n",
            "720 jobs were scraped\n",
            "48 pages were scraped\n",
            "735 jobs were scraped\n",
            "49 pages were scraped\n",
            "750 jobs were scraped\n",
            "50 pages were scraped\n",
            "765 jobs were scraped\n",
            "51 pages were scraped\n",
            "780 jobs were scraped\n",
            "52 pages were scraped\n",
            "795 jobs were scraped\n",
            "53 pages were scraped\n",
            "810 jobs were scraped\n",
            "54 pages were scraped\n",
            "825 jobs were scraped\n",
            "55 pages were scraped\n",
            "840 jobs were scraped\n",
            "56 pages were scraped\n",
            "855 jobs were scraped\n",
            "57 pages were scraped\n",
            "870 jobs were scraped\n",
            "58 pages were scraped\n",
            "885 jobs were scraped\n",
            "59 pages were scraped\n",
            "900 jobs were scraped\n",
            "60 pages were scraped\n",
            "915 jobs were scraped\n",
            "61 pages were scraped\n",
            "930 jobs were scraped\n",
            "62 pages were scraped\n",
            "945 jobs were scraped\n",
            "63 pages were scraped\n",
            "960 jobs were scraped\n",
            "64 pages were scraped\n",
            "975 jobs were scraped\n",
            "65 pages were scraped\n",
            "990 jobs were scraped\n",
            "66 pages were scraped\n",
            "1005 jobs were scraped\n",
            "67 pages were scraped\n",
            "1020 jobs were scraped\n",
            "68 pages were scraped\n",
            "1035 jobs were scraped\n",
            "69 pages were scraped\n",
            "1050 jobs were scraped\n",
            "70 pages were scraped\n",
            "1061 jobs were scraped\n",
            "71 pages were scraped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted_skills)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp10sEYOmLIa",
        "outputId": "fd62150d-9f4e-4122-9491-89b7d50254f5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'computer science': 46, 'information technology (it)': 45, 'python': 17, 'engineering': 17, 'sql': 16, 'analysis': 8, 'sales': 8, 'marketing': 8, 'finance': 7, 'financial analysis': 7, 'accounting': 7, 'data analysis': 6, 'customer service': 6, 'sales skills': 6, 'software engineering': 5, 'software development': 5, 'project management': 5, 'computer engineering': 4, 'financial management': 4, 'machine learning': 4, 'javascript': 4, 'human resources (hr)': 3, 'commerce': 3, 'science': 3, 'full stack': 3, 'ai': 3, 'artificial intelligence': 3, 'manufacturing': 3, 'social media': 3, 'customer care': 3, 'recruitment': 2, 'azure': 2, 'business intelligence': 2, 'html': 2, 'business development': 2, 'management': 2, 'chemistry': 2, 'dcs': 2, 'electrical engineering': 2, 'market research': 2, 'mechanical engineering': 2, 'business analysis': 2, 'e-marketing': 2, 'customer support': 2, 'mathematics': 1, 'data science': 1, 'labor law': 1, 'training': 1, 'data mining': 1, 'database': 1, 'data': 1, 'data visualization': 1, 'big data': 1, 'data modeling': 1, 'php': 1, 'jquery': 1, 'mysql': 1, 'css': 1, 'react': 1, 'livewire': 1, 'front-end development': 1, 'bi': 1, 'power bi': 1, 'power apps': 1, 'oracle': 1, 'chemical': 1, 'chemical engineering': 1, 'flavors': 1, 'asp': 1, 'asp.net': 1, '.net': 1, 'blazor': 1, 'mvc': 1, 'asp.net core': 1, 'c#.net': 1, 'business': 1, 'pneumatic': 1, 'hydraulic': 1, 'mechanical power engineering': 1, 'r&amp;d': 1, 'deep learning': 1, 'computer vision': 1, 'agricultural engineer': 1, 'agricultural engineering': 1, 'agronomist': 1, 'laravel': 1, 'laravel 5': 1, 'laravel php': 1, 'design': 1, 'pharmacy': 1, 'research': 1, 'pmp': 1, 'c#': 1, 'branding': 1, 'production': 1, 'call center': 1, 'talent acquisition': 1, 'interviewing': 1, 'hse': 1, 'health &amp; safety': 1, 'sales target': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ZFJBsFemgtt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}